{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD,Adagrad, Adadelta, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86108228, 0.99524268, 0.274512  , ..., 0.53731849, 0.82773079,\n",
       "        0.68980885],\n",
       "       [0.25088614, 0.93150421, 0.22172361, ..., 0.36482609, 0.22475562,\n",
       "        0.72125103],\n",
       "       [0.31073636, 0.65718982, 0.71561134, ..., 0.84644215, 0.22985518,\n",
       "        0.18679091],\n",
       "       ...,\n",
       "       [0.74764249, 0.80803105, 0.66112106, ..., 0.62115948, 0.11954591,\n",
       "        0.8350158 ],\n",
       "       [0.97361005, 0.32484802, 0.39129604, ..., 0.55764411, 0.94607136,\n",
       "        0.3476408 ],\n",
       "       [0.24747932, 0.90575282, 0.75183311, ..., 0.39454875, 0.70398393,\n",
       "        0.22315992]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 319us/step - loss: 2.3414 - acc: 0.1180\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.3272 - acc: 0.1130\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 2.3097 - acc: 0.1010\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 2.3115 - acc: 0.0910\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 2.3102 - acc: 0.1060\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 2.3001 - acc: 0.1050\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 2.3073 - acc: 0.0920\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 2.2952 - acc: 0.1100\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 2.3012 - acc: 0.1200\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 2.2960 - acc: 0.1200\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 2.3001 - acc: 0.1070\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 2.2985 - acc: 0.0980\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 2.2962 - acc: 0.1190\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 2.2945 - acc: 0.1170\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 2.2965 - acc: 0.1360\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 106us/step - loss: 2.2909 - acc: 0.1410\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 123us/step - loss: 2.2922 - acc: 0.1180\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 2.2964 - acc: 0.1310\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 118us/step - loss: 2.2897 - acc: 0.1200\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 133us/step - loss: 2.2876 - acc: 0.1420\n",
      "100/100 [==============================] - 0s 782us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs = 20, batch_size= 32)\n",
    "score = model.evaluate(x_test, y_test, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.317858352661133, 0.09]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, Adadelta,adagrad, rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "X_train = np.random.random((1000, 2))\n",
    "Y_train = keras.utils.to_categorical(np.random.randint(2, size = (1000, 1)), num_classes= 2)\n",
    "X_test = np.random.random((100,2))\n",
    "Y_test = keras.utils.to_categorical(np.random.randint(2, size = (100, 1)), num_classes= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation= 'relu', input_dim = 2))\n",
    "model1.add(Dense(64, activation = 'relu'))\n",
    "model1.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss = 'binary_crossentropy', optimizer= 'rmsprop', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.6905 - acc: 0.5300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.6899 - acc: 0.5260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.6907 - acc: 0.5290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.6905 - acc: 0.5260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.6904 - acc: 0.5290\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.6902 - acc: 0.5300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.6906 - acc: 0.5210\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.6905 - acc: 0.5290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.6899 - acc: 0.5250\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.6898 - acc: 0.5230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282e0fa4c50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,Y_train, epochs = 10, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7062636017799377, 0.4300000071525574]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, Y_test, batch_size= 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-like convet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adam, adagrad, rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the dummy data \n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size = (100, 1)), num_classes= 10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size = (20,1)), num_classes= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.28270582 0.49160121 0.78219757]\n",
      "   [0.19231449 0.9708901  0.21635187]\n",
      "   [0.56205806 0.02597156 0.95553157]\n",
      "   ...\n",
      "   [0.04148871 0.63022408 0.3726149 ]\n",
      "   [0.5841292  0.23282061 0.46006192]\n",
      "   [0.32503608 0.10801225 0.79056636]]\n",
      "\n",
      "  [[0.05638819 0.86679716 0.09489613]\n",
      "   [0.45671117 0.22261168 0.32855956]\n",
      "   [0.44064072 0.32465476 0.23934242]\n",
      "   ...\n",
      "   [0.45714279 0.19710152 0.50887989]\n",
      "   [0.48184605 0.25062309 0.95409808]\n",
      "   [0.03018942 0.38752317 0.85901128]]\n",
      "\n",
      "  [[0.35820392 0.59808167 0.22935239]\n",
      "   [0.77740446 0.66984558 0.27060891]\n",
      "   [0.96167175 0.40559523 0.65732775]\n",
      "   ...\n",
      "   [0.76733118 0.34125094 0.47367428]\n",
      "   [0.80915117 0.46411051 0.77072145]\n",
      "   [0.35712915 0.51922134 0.14712915]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10741721 0.67444663 0.22935828]\n",
      "   [0.27348752 0.43166481 0.32012881]\n",
      "   [0.96578425 0.59754255 0.50533862]\n",
      "   ...\n",
      "   [0.0118613  0.45469186 0.07782329]\n",
      "   [0.62187185 0.63765389 0.05394874]\n",
      "   [0.77022106 0.685339   0.05435114]]\n",
      "\n",
      "  [[0.63685465 0.64405749 0.62578472]\n",
      "   [0.65642793 0.87910137 0.83210906]\n",
      "   [0.78452963 0.93971722 0.35341093]\n",
      "   ...\n",
      "   [0.42444824 0.75619087 0.47043399]\n",
      "   [0.91663559 0.83162692 0.3976079 ]\n",
      "   [0.41846498 0.39604419 0.89117378]]\n",
      "\n",
      "  [[0.90639612 0.85268196 0.47594176]\n",
      "   [0.31522715 0.31020217 0.15811957]\n",
      "   [0.98202662 0.44642901 0.13590874]\n",
      "   ...\n",
      "   [0.23714952 0.12258704 0.75935933]\n",
      "   [0.1177879  0.19283607 0.58076498]\n",
      "   [0.07983173 0.04174317 0.16681663]]]\n",
      "\n",
      "\n",
      " [[[0.79563539 0.98142612 0.19045762]\n",
      "   [0.74100852 0.80531838 0.91121825]\n",
      "   [0.10333962 0.20158794 0.67843185]\n",
      "   ...\n",
      "   [0.04784209 0.40956876 0.56041963]\n",
      "   [0.31003706 0.59245283 0.08172062]\n",
      "   [0.32894061 0.83714571 0.1390426 ]]\n",
      "\n",
      "  [[0.86089667 0.37084103 0.39558955]\n",
      "   [0.68567242 0.08969927 0.88745915]\n",
      "   [0.23262834 0.22636611 0.67257741]\n",
      "   ...\n",
      "   [0.1072621  0.76096717 0.38686058]\n",
      "   [0.64410184 0.11996535 0.75985298]\n",
      "   [0.51459469 0.48409988 0.22299663]]\n",
      "\n",
      "  [[0.42490141 0.24604983 0.80002458]\n",
      "   [0.96803452 0.32265394 0.48228711]\n",
      "   [0.04272212 0.86312002 0.15903742]\n",
      "   ...\n",
      "   [0.84119334 0.10652784 0.70384971]\n",
      "   [0.03604865 0.8194568  0.91468865]\n",
      "   [0.97186337 0.51408266 0.67478473]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9184122  0.06926601 0.125967  ]\n",
      "   [0.44334771 0.85167064 0.27202809]\n",
      "   [0.79141485 0.73853947 0.558193  ]\n",
      "   ...\n",
      "   [0.65709009 0.57433579 0.19236455]\n",
      "   [0.53172919 0.7267944  0.83012123]\n",
      "   [0.65143608 0.03154603 0.81709748]]\n",
      "\n",
      "  [[0.47854463 0.39876595 0.35242658]\n",
      "   [0.67734694 0.31752782 0.01963227]\n",
      "   [0.19294992 0.79531993 0.43172486]\n",
      "   ...\n",
      "   [0.38017935 0.0207848  0.60511768]\n",
      "   [0.58393607 0.12472708 0.47557162]\n",
      "   [0.61178016 0.96595129 0.30468066]]\n",
      "\n",
      "  [[0.50928042 0.56281386 0.26006996]\n",
      "   [0.62204881 0.21528639 0.16251262]\n",
      "   [0.69515094 0.68740816 0.10875362]\n",
      "   ...\n",
      "   [0.7750773  0.58931469 0.70101321]\n",
      "   [0.2493306  0.92385924 0.21878725]\n",
      "   [0.5447162  0.66200255 0.01157926]]]\n",
      "\n",
      "\n",
      " [[[0.25372181 0.99212082 0.20595515]\n",
      "   [0.4462953  0.19697405 0.6120479 ]\n",
      "   [0.70428716 0.69762129 0.0848752 ]\n",
      "   ...\n",
      "   [0.36676464 0.03330095 0.76254574]\n",
      "   [0.08415347 0.18823514 0.12739376]\n",
      "   [0.76594595 0.32945177 0.90538319]]\n",
      "\n",
      "  [[0.74615226 0.44407113 0.89818901]\n",
      "   [0.1874041  0.01526533 0.2003329 ]\n",
      "   [0.64471443 0.31912102 0.98529446]\n",
      "   ...\n",
      "   [0.84793596 0.95637686 0.84041964]\n",
      "   [0.75994993 0.6005997  0.1275082 ]\n",
      "   [0.48141728 0.30007887 0.35070089]]\n",
      "\n",
      "  [[0.59035975 0.29091723 0.7053405 ]\n",
      "   [0.47258868 0.97481611 0.25955378]\n",
      "   [0.8861453  0.97420066 0.86140378]\n",
      "   ...\n",
      "   [0.57220581 0.08338321 0.97775565]\n",
      "   [0.21665254 0.94634109 0.30873956]\n",
      "   [0.90848638 0.68181908 0.97586337]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.31242815 0.32258827 0.34964278]\n",
      "   [0.07174991 0.99948853 0.9843143 ]\n",
      "   [0.17564546 0.62549117 0.65632009]\n",
      "   ...\n",
      "   [0.16642109 0.38657405 0.62446214]\n",
      "   [0.37258507 0.45096668 0.41880657]\n",
      "   [0.76466298 0.32531195 0.92858129]]\n",
      "\n",
      "  [[0.57325526 0.55504572 0.76432527]\n",
      "   [0.67747977 0.33280548 0.14874099]\n",
      "   [0.90188813 0.34994595 0.17573817]\n",
      "   ...\n",
      "   [0.77061142 0.03984779 0.82131132]\n",
      "   [0.86521636 0.01690255 0.08077915]\n",
      "   [0.36088291 0.98865503 0.4605396 ]]\n",
      "\n",
      "  [[0.11649137 0.74524398 0.81986919]\n",
      "   [0.77215378 0.42081869 0.09869487]\n",
      "   [0.61076594 0.59804443 0.01428936]\n",
      "   ...\n",
      "   [0.31985831 0.86698914 0.93325553]\n",
      "   [0.8316593  0.31399779 0.70229855]\n",
      "   [0.56081233 0.96282997 0.50402382]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.59127069 0.66596427 0.47593801]\n",
      "   [0.67561947 0.13516989 0.4847173 ]\n",
      "   [0.2252198  0.47360834 0.38394595]\n",
      "   ...\n",
      "   [0.84485046 0.11373597 0.77437521]\n",
      "   [0.20204994 0.87794813 0.47770323]\n",
      "   [0.09395465 0.4387073  0.04726653]]\n",
      "\n",
      "  [[0.16852453 0.59497558 0.09346147]\n",
      "   [0.31605278 0.90775361 0.16318815]\n",
      "   [0.01836399 0.9945959  0.41828876]\n",
      "   ...\n",
      "   [0.67613146 0.33021022 0.56953227]\n",
      "   [0.72613832 0.21231924 0.36109182]\n",
      "   [0.91237606 0.64216859 0.21188251]]\n",
      "\n",
      "  [[0.79212331 0.63486219 0.27550412]\n",
      "   [0.92679172 0.60477845 0.21631551]\n",
      "   [0.22897734 0.18233372 0.85185777]\n",
      "   ...\n",
      "   [0.16598515 0.09933184 0.58042055]\n",
      "   [0.3277025  0.8137277  0.30210266]\n",
      "   [0.95214859 0.39553343 0.03847251]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.84983327 0.83370144 0.85167453]\n",
      "   [0.44997906 0.43891055 0.55203617]\n",
      "   [0.84239608 0.69017905 0.86011471]\n",
      "   ...\n",
      "   [0.46472894 0.67330394 0.13139852]\n",
      "   [0.83328699 0.64953678 0.73723881]\n",
      "   [0.53669662 0.29958939 0.26723103]]\n",
      "\n",
      "  [[0.66982428 0.909117   0.55710995]\n",
      "   [0.75017684 0.63424911 0.71575577]\n",
      "   [0.34772259 0.71040411 0.76987195]\n",
      "   ...\n",
      "   [0.64910325 0.09978312 0.38437048]\n",
      "   [0.77238598 0.16571012 0.16364235]\n",
      "   [0.59594516 0.96012705 0.31879787]]\n",
      "\n",
      "  [[0.44435696 0.06742799 0.13686777]\n",
      "   [0.55871185 0.49087782 0.04775218]\n",
      "   [0.05817055 0.46414778 0.90064236]\n",
      "   ...\n",
      "   [0.90970973 0.89163599 0.5271279 ]\n",
      "   [0.54635084 0.91357101 0.78590493]\n",
      "   [0.13193982 0.26847957 0.70130862]]]\n",
      "\n",
      "\n",
      " [[[0.38443231 0.30454207 0.78115489]\n",
      "   [0.72147878 0.07803919 0.63108464]\n",
      "   [0.35749019 0.20365673 0.42969458]\n",
      "   ...\n",
      "   [0.58255447 0.92892569 0.91725568]\n",
      "   [0.85600905 0.56915985 0.87315124]\n",
      "   [0.38073825 0.38705693 0.8862212 ]]\n",
      "\n",
      "  [[0.89462831 0.62571319 0.67203474]\n",
      "   [0.54022404 0.83185975 0.19519671]\n",
      "   [0.61330679 0.56819795 0.9739524 ]\n",
      "   ...\n",
      "   [0.5045436  0.00776075 0.8871027 ]\n",
      "   [0.49158108 0.95507518 0.17543517]\n",
      "   [0.35056809 0.75220423 0.90574222]]\n",
      "\n",
      "  [[0.29809786 0.12968161 0.16864357]\n",
      "   [0.51411172 0.012554   0.409698  ]\n",
      "   [0.64072038 0.93990605 0.11055427]\n",
      "   ...\n",
      "   [0.89490384 0.82506892 0.626386  ]\n",
      "   [0.74468142 0.38320997 0.02877614]\n",
      "   [0.92816266 0.62164621 0.31706274]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28454567 0.32779742 0.99686823]\n",
      "   [0.08407194 0.97135625 0.96011685]\n",
      "   [0.82784377 0.85440628 0.33716853]\n",
      "   ...\n",
      "   [0.1762425  0.75448696 0.2867495 ]\n",
      "   [0.43957672 0.05728069 0.35092726]\n",
      "   [0.39394841 0.19187665 0.087506  ]]\n",
      "\n",
      "  [[0.37053724 0.14621092 0.08038367]\n",
      "   [0.6987581  0.98226874 0.96961981]\n",
      "   [0.09683272 0.663163   0.47510716]\n",
      "   ...\n",
      "   [0.58568818 0.90872611 0.69820007]\n",
      "   [0.64973964 0.2686858  0.13156921]\n",
      "   [0.54802771 0.5709564  0.82636747]]\n",
      "\n",
      "  [[0.65883349 0.00909089 0.4436071 ]\n",
      "   [0.78698728 0.10694985 0.02143114]\n",
      "   [0.63296079 0.2583708  0.93906046]\n",
      "   ...\n",
      "   [0.72772323 0.33371389 0.48268839]\n",
      "   [0.53461598 0.41709738 0.55186231]\n",
      "   [0.64774826 0.6632811  0.89049107]]]\n",
      "\n",
      "\n",
      " [[[0.16551706 0.11048649 0.81000287]\n",
      "   [0.06871254 0.00817651 0.32185892]\n",
      "   [0.2403683  0.40018847 0.57367611]\n",
      "   ...\n",
      "   [0.80985329 0.70709864 0.79309977]\n",
      "   [0.14833898 0.15929533 0.96556117]\n",
      "   [0.48633779 0.23553412 0.72542207]]\n",
      "\n",
      "  [[0.81800227 0.29209636 0.73356483]\n",
      "   [0.80241506 0.08499695 0.05399906]\n",
      "   [0.42182661 0.69816721 0.05112744]\n",
      "   ...\n",
      "   [0.44631046 0.05103411 0.23806711]\n",
      "   [0.47835746 0.75746413 0.20950627]\n",
      "   [0.91893748 0.48580264 0.7933381 ]]\n",
      "\n",
      "  [[0.05927208 0.79324236 0.43013054]\n",
      "   [0.48638026 0.92720479 0.68485962]\n",
      "   [0.32053546 0.24758519 0.23711892]\n",
      "   ...\n",
      "   [0.44001674 0.27641382 0.99239658]\n",
      "   [0.66306571 0.17118293 0.13114682]\n",
      "   [0.6427304  0.36150354 0.69794988]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.73534352 0.67227693 0.99374976]\n",
      "   [0.1037303  0.79813202 0.80082633]\n",
      "   [0.6299091  0.71508138 0.97166653]\n",
      "   ...\n",
      "   [0.36380165 0.75679896 0.38643946]\n",
      "   [0.65975766 0.49734056 0.58242132]\n",
      "   [0.70652097 0.75239425 0.41898461]]\n",
      "\n",
      "  [[0.61042556 0.603676   0.49774046]\n",
      "   [0.75040377 0.96976259 0.78506533]\n",
      "   [0.41167808 0.07163718 0.18276897]\n",
      "   ...\n",
      "   [0.80829461 0.80278088 0.06516362]\n",
      "   [0.79595137 0.82796182 0.06038282]\n",
      "   [0.98782457 0.15212209 0.88010637]]\n",
      "\n",
      "  [[0.2483453  0.65703343 0.9729908 ]\n",
      "   [0.11373089 0.35882362 0.58168491]\n",
      "   [0.43162923 0.177235   0.9623963 ]\n",
      "   ...\n",
      "   [0.60977439 0.7136552  0.06211044]\n",
      "   [0.43559146 0.71693595 0.68116192]\n",
      "   [0.96176307 0.58501107 0.80074506]]]]\n"
     ]
    }
   ],
   "source": [
    "x_train.shape\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.1, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'rmsprop', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 5.9654 - acc: 0.1100\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 2.2977 - acc: 0.1300\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 2.3796 - acc: 0.0800\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 2.3027 - acc: 0.1100\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 2.2987 - acc: 0.0800\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 2.2990 - acc: 0.1500\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 2.2996 - acc: 0.0700\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 2.2984 - acc: 0.1000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 2.2982 - acc: 0.1000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 2.2971 - acc: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20899d98f98>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size= 32, epochs= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3695788383483887, 0.05000000074505806]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence classification with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences= True,\n",
    "              input_shape = (timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences= True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.random.random((1000, timesteps, data_dim))\n",
    "Y_train = np.random.random((1000, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = np.random.random((1000, timesteps, data_dim))\n",
    "Y_val = np.random.random((1000, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.5072 - acc: 0.0940 - val_loss: 11.5801 - val_acc: 0.0880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 728us/step - loss: 11.5052 - acc: 0.0870 - val_loss: 11.5806 - val_acc: 0.1130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 731us/step - loss: 11.5052 - acc: 0.1030 - val_loss: 11.5790 - val_acc: 0.1150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 746us/step - loss: 11.5046 - acc: 0.1040 - val_loss: 11.5814 - val_acc: 0.0910\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 769us/step - loss: 11.5041 - acc: 0.0980 - val_loss: 11.5796 - val_acc: 0.1070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 754us/step - loss: 11.5038 - acc: 0.1190 - val_loss: 11.5809 - val_acc: 0.0940\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 739us/step - loss: 11.5033 - acc: 0.1080 - val_loss: 11.5793 - val_acc: 0.1030\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 755us/step - loss: 11.5028 - acc: 0.1140 - val_loss: 11.5798 - val_acc: 0.0780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 838us/step - loss: 11.5027 - acc: 0.1110 - val_loss: 11.5817 - val_acc: 0.0770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 757us/step - loss: 11.5024 - acc: 0.1090 - val_loss: 11.5792 - val_acc: 0.1130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208a1f572b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, verbose= 1, epochs= 10, batch_size= 32, validation_data= (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "Y_train = np.random.random((batch_size * 10, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "Y_val = np.random.random((batch_size * 3, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 96 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 0s 434us/step - loss: 11.3646 - acc: 0.1000 - val_loss: 11.7897 - val_acc: 0.2083\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 0s 512us/step - loss: 11.3634 - acc: 0.0969 - val_loss: 11.7871 - val_acc: 0.1875\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - 0s 463us/step - loss: 11.3639 - acc: 0.1031 - val_loss: 11.7901 - val_acc: 0.1458\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 0s 457us/step - loss: 11.3644 - acc: 0.0969 - val_loss: 11.7889 - val_acc: 0.1146\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 0s 502us/step - loss: 11.3638 - acc: 0.1000 - val_loss: 11.7875 - val_acc: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208acbdde10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=5, shuffle=True,validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# how can i remove the  layer from sequential model\n",
    "model= Sequential()\n",
    "model.add(Dense(10, input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "print(len(model.layers))\n",
    "model.pop()\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can i use pre-trained models  in keras\n",
    "# from keras application we can import \n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
